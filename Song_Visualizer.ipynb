{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Subramanian\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:862: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from rake_nltk import Rake\n",
    "import pandas as pd\n",
    "import requests\n",
    "from IPython.display import Image, display\n",
    "from timeit import default_timer as timer\n",
    "import pprint\n",
    "import sys\n",
    "from timeit import default_timer as timer\n",
    "import gensim\n",
    "import string\n",
    "from gensim.models import word2vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Utilities\n",
    "def print_song_keywords(Song_Name):\n",
    "    rake = Rake()\n",
    "    rake.extract_keywords_from_text(get_song(Song_Name))\n",
    "    for i in range(0,len(rake.get_ranked_phrases_with_scores())):\n",
    "        print(str(rake.get_ranked_phrases_with_scores()[i]))\n",
    "\n",
    "def extract_song_keywords(Song_Name):\n",
    "    rake = Rake()\n",
    "    return rake.extract_keywords_from_text(get_song(Song_Name))\n",
    "\n",
    "def get_song(title):\n",
    "    return Songs.loc[title][\"text\"]\n",
    "\n",
    "def print_song(title):\n",
    "    print(get_song(title))\n",
    "    \n",
    "def createDict(keywords,N):\n",
    "    Dict = {}\n",
    "    r = requests.get('https://pixabay.com/api/?key=6713313-c85a6d8e3f6fe1a13b85f7d78&q='+\"+\".join(keywords)+'&image_type=photo&page=1&per_page='+str(N))\n",
    "    for img in r.json()['hits']:\n",
    "        Dict[img['webformatURL']] = img[\"tags\"].split(\",\")\n",
    "    return Dict\n",
    "\n",
    "def displayDict(Dict,limit):\n",
    "    i = 1\n",
    "    urls = Dict.keys()\n",
    "    \n",
    "    for url in urls:\n",
    "        print(url)\n",
    "        print(Dict[url])\n",
    "        display(Image(url,height=700,width=1000,embed=True))\n",
    "        print(\"\\n\")\n",
    "        if(i == limit): \n",
    "            break\n",
    "        i += 1\n",
    "        \n",
    "def get_mean_of_words(tags):\n",
    "    mean = []\n",
    "    for i in range(300):\n",
    "         mean.append(0)\n",
    "    size = len(tags)\n",
    "    for tag in tags:\n",
    "        mean += nlp.word_vec(tag.lower().replace(\" \", \"\")) \n",
    "    \n",
    "    mean = mean/size\n",
    "    return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pre-processing\n",
    "Songs = pd.read_csv(\"songdata.csv\")\n",
    "Songs.set_index(\"song\",inplace=True)\n",
    "Songs.drop([\"artist\",\"link\"],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'll never know why I had to go  \\nWhy I had to put up such a lousy rotten show  \\nBoy, I was tough, packing all my stuff  \\nSaying I don't need you anymore, I've had enough  \\nAnd now, look at me standing here again 'cause I found out that  \\nMa ma ma ma ma ma ma ma ma ma ma ma ma ma ma ma my life is here  \\nGotta have you near  \\n  \\nAs good as new, my love for you  \\nAnd keeping it that way is my intention  \\nAs good as new and growing too  \\nYes, I think it's taking on a new dimension  \\nIt's as good as new, my love for you  \\nJust like it used to be and even better  \\nAs good as new, thank God it's true  \\nDarling, we were always meant to stay together  \\n  \\nFeel like a creep, never felt so cheap  \\nNever had a notion that my love could be so deep  \\nHow could I make such a dumb mistake  \\nNow I know I'm not entitled to another break  \\nBut please, baby, I beg you to forgive 'cause I found out that  \\nMa ma ma ma ma ma ma ma ma ma ma ma ma ma ma ma my life is here  \\nGotta get you near  \\n  \\nI thought that our love was at an end but here I am again  \\n  \\nAs good as new, my love for you  \\nAnd keeping it that way is my intention  \\nAs good as new and growing too  \\nYes, I think it's taking on a new dimension  \\nIt's as good as new, my love for you  \\nJust like it used to be and even better  \\nAs good as new, thank God it's true  \\nDarling, we were always meant to stay together  \\n  \\nYes the love I have for you feels as good as new  \\nDarling, we were always meant to stay together\\n\\n\""
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Songs.iloc[2][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'll never know why I had to go  \n",
      "Why I had to put up such a lousy rotten show  \n",
      "Boy, I was tough, packing all my stuff  \n",
      "Saying I don't need you anymore, I've had enough  \n",
      "And now, look at me standing here again 'cause I found out that  \n",
      "Ma ma ma ma ma ma ma ma ma ma ma ma ma ma ma ma my life is here  \n",
      "Gotta have you near  \n",
      "  \n",
      "As good as new, my love for you  \n",
      "And keeping it that way is my intention  \n",
      "As good as new and growing too  \n",
      "Yes, I think it's taking on a new dimension  \n",
      "It's as good as new, my love for you  \n",
      "Just like it used to be and even better  \n",
      "As good as new, thank God it's true  \n",
      "Darling, we were always meant to stay together  \n",
      "  \n",
      "Feel like a creep, never felt so cheap  \n",
      "Never had a notion that my love could be so deep  \n",
      "How could I make such a dumb mistake  \n",
      "Now I know I'm not entitled to another break  \n",
      "But please, baby, I beg you to forgive 'cause I found out that  \n",
      "Ma ma ma ma ma ma ma ma ma ma ma ma ma ma ma ma my life is here  \n",
      "Gotta get you near  \n",
      "  \n",
      "I thought that our love was at an end but here I am again  \n",
      "  \n",
      "As good as new, my love for you  \n",
      "And keeping it that way is my intention  \n",
      "As good as new and growing too  \n",
      "Yes, I think it's taking on a new dimension  \n",
      "It's as good as new, my love for you  \n",
      "Just like it used to be and even better  \n",
      "As good as new, thank God it's true  \n",
      "Darling, we were always meant to stay together  \n",
      "  \n",
      "Yes the love I have for you feels as good as new  \n",
      "Darling, we were always meant to stay together\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(Songs.iloc[2][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: \n",
      "\n",
      "I'll never know why I had to go  \n",
      "Why I had to put up such a lousy rotten show  \n",
      "Boy, I was tough, packing all my stuff  \n",
      "Saying I don't need you anymore, I've had enough  \n",
      "And now, look at me standing here again 'cause I found out that  \n",
      "Ma ma ma ma ma ma ma ma ma ma ma ma ma ma ma ma my life is here  \n",
      "Gotta have you near  \n",
      "  \n",
      "As good as new, my love for you  \n",
      "And keeping it that way is my intention  \n",
      "As good as new and growing too  \n",
      "Yes, I think it's taking on a new dimension  \n",
      "It's as good as new, my love for you  \n",
      "Just like it used to be and even better  \n",
      "As good as new, thank God it's true  \n",
      "Darling, we were always meant to stay together  \n",
      "  \n",
      "Feel like a creep, never felt so cheap  \n",
      "Never had a notion that my love could be so deep  \n",
      "How could I make such a dumb mistake  \n",
      "Now I know I'm not entitled to another break  \n",
      "But please, baby, I beg you to forgive 'cause I found out that  \n",
      "Ma ma ma ma ma ma ma ma ma ma ma ma ma ma ma ma my life is here  \n",
      "Gotta get you near  \n",
      "  \n",
      "I thought that our love was at an end but here I am again  \n",
      "  \n",
      "As good as new, my love for you  \n",
      "And keeping it that way is my intention  \n",
      "As good as new and growing too  \n",
      "Yes, I think it's taking on a new dimension  \n",
      "It's as good as new, my love for you  \n",
      "Just like it used to be and even better  \n",
      "As good as new, thank God it's true  \n",
      "Darling, we were always meant to stay together  \n",
      "  \n",
      "Yes the love I have for you feels as good as new  \n",
      "Darling, we were always meant to stay together\n",
      "\n",
      "\n",
      "2: \n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "k = 1\n",
    "for i in Songs.iloc[2][\"text\"].split(breaker):\n",
    "    \n",
    "    print(str(k) + \": \\n\")\n",
    "    print(i)\n",
    "    print(\"\\n\")\n",
    "    k = k + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'squeezes', 'sees', 'talking', 'makes', 'ever leaves', 'girl', 'mine', 'go', 'blue', 'way', 'plan', 'lucky', 'face', 'smiles', 'walk', 'hours', 'look', 'walking', 'could ever believe', 'feel fine', 'kind', 'without', 'could', 'wonderful face', 'hand', 'things', 'means something special', 'one fellow', 'park', 'holds'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "breaker = \"\\n\\n\"\n",
    "for i in Songs.iloc[0][\"text\"].split(breaker):\n",
    "    rake = Rake()\n",
    "    rake.extract_keywords_from_text(i)\n",
    "    A = rake.get_ranked_phrases_with_scores()\n",
    "    if not A:\n",
    "          continue\n",
    "    keywords = set(pd.DataFrame(A)[1])\n",
    "    print(keywords)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time taken:           0.8455145809820555\n",
      "Size of Table Element:         200\n"
     ]
    }
   ],
   "source": [
    "# Song Name -> List of URLS\n",
    "\n",
    "Max_number_of_search_results = 200\n",
    "\n",
    "start    = timer()\n",
    "keywords = ['radio']\n",
    "Dict     = createDict(keywords, Max_number_of_search_results)\n",
    "\n",
    "print(\"\\nTime taken:           \" +  str(timer() - start) + \"\\nSize of Table Element:         \" + str(len(Dict.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.50886606923978 seconds\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', limit=2000000, binary=True)\n",
    "print(str(timer() - start) + \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['radio', ' old', ' nostalgia']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = list(Dict.values())[8]\n",
    "\n",
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "radio-> [('radio_stations', 0.7330180406570435), ('Radio', 0.7293578386306763), ('FM_radio', 0.6507300138473511)]\n",
      "\n",
      "\n",
      " old-> [('yearold', 0.7316408753395081), ('boy', 0.5828141570091248), ('0ld', 0.552962601184845)]\n",
      "\n",
      "\n",
      " nostalgia-> [('nostalgic', 0.7928276062011719), ('Nostalgia', 0.662556529045105), ('sentimentality', 0.6507173776626587)]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# vector of similiar words to each tag\n",
    "for tag in tags:\n",
    "    # just a way to convert keywords into a form that can be submitted to a query\n",
    "    filteredform = \"\".join((char for char in tag.lower().strip() if char not in string.punctuation))\n",
    "    print(tag + \"-> \" + str(model.wv.most_similar(filteredform,topn=3)))\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'testing case'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"^^^^^^^^^^^testing case!!!!!\"\n",
    " \n",
    "\"\".join((char for char in s.lower().strip() if char not in string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "max_images = 200\n",
    "for i in range(0,len(Songs)):\n",
    "    paras = Songs.iloc[i][\"text\"].split(\"\\n \\n\")\n",
    "    for para in paras:\n",
    "        rake = Rake()\n",
    "        rake.extract_keywords_from_text(para)\n",
    "        rake.get_ranked_phrases_with_scores()\n",
    "        print(kwys)\n",
    "        \n",
    "       # for kyw in kyws:\n",
    "          #  createDict(keywords,max_images)\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createDict(keywords,N):\n",
    "    Dict = {}\n",
    "    r = requests.get('https://pixabay.com/api/?key=6713313-c85a6d8e3f6fe1a13b85f7d78&q='+\"+\".join(keywords)+'&image_type=photo&page=1&per_page='+str(N))\n",
    "    for img in r.json()['hits']:\n",
    "        Dict[img['webformatURL']] = img[\"tags\"].split(\",\")\n",
    "    return Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['radio', ' old', ' nostalgia']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = get_mean_of_words(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "B;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
